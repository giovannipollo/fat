# Dual Fault Injection Configuration
# Uses both activation and weight fault injection

seed:
  enabled: true
  value: 42
  deterministic: false

dataset:
  name: "cifar10"
  root: "./data"
  download: true
  num_workers: 4

model:
  name: "quant_cnv"

quantization:
  in_weight_bit_width: 8
  weight_bit_width: 4
  act_bit_width: 4

loss:
  name: "sqr_hinge"

training:
  batch_size: 256

optimizer:
  name: "adam"
  learning_rate: 0.01
  weight_decay: 0.0

scheduler:
  name: "cosine"
  warmup_epochs: 0

activation_fault_injection:
  enabled: false
  probability: 0.0
  injection_type: "random"
  apply_during: "eval"
  target_layers: ["QuantReLU"]
  track_statistics: false
  verbose: false

weight_fault_injection:
  enabled: false

amp:
  enabled: false

tensorboard:
  enabled: true

progress:
  enabled: true

checkpoint:
  enabled: true
  dir: "./experiments"
  save_frequency: 50
  save_best: true

phases:
  # Phase 1: Standard training
  - name: "standard_training"
    epochs: 150
    scheduler:
      T_max: 150

  # Phase 2: Dual fault injection
  - name: "dual_fault_injection"
    epochs: 100

    optimizer:
      learning_rate: 0.001

    scheduler:
      T_max: 100

    activation_fault_injection:
      enabled: true
      probability: 5.0
      injection_type: "random"
      apply_during: "train"
      target_layers: ["QuantReLU"]
      track_statistics: true

    weight_fault_injection:
      enabled: true
      probability: 5.0
      injection_type: "random"
      apply_during: "train"
      target_layers: ["QuantConv2d"]
      track_statistics: true
